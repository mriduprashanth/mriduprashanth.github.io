VR headsets simulate real world scenarios that are immersive, interactive, and imaginative. They are used as a training tool in a variety of fields from construction to medicine to education. Effective real-time computation is challenged by VR's limited rendering power. We describe a novel stochastic visibility algorithm for accurately and speedily displaying complex Virtual Environments (VEs) on demand during navigation by pre-computing an aggressive visible set with chosen granularity of scene components (triangles, meshes) for various scenes. Given a 3D region (view cube or view square), the algorithm finds a fraction of the original set of scene components required to render the scene from within the view region – preserving far away, out of view and currently occluded but later visible components. This offers about a 40% reduction in the visible set of triangles, speeding up on-demand rendering. VECMA-3SV is single shot with raytracing performed only once per unit of the view region, making it less expensive than state of the art methods that ray trace continuously multiple times along a view region segment. Since our view region for raytracing allows a larger field of view, our scenes average errors within 0.05% compared against ground truth and are virtually indistinguishable from it. Accordingly, the peak signal to noise ratio averages 35 dB (considered good), with the structural similarity index being very close to 1 along the full walk around the perimeter of the view region, which is at the very edge so has the least visibility in the view region. This showcases the model’s potential for use in real-time applications. 
