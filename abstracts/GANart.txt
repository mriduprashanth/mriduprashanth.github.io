A class of artificial models motivated by biological vision, known as Deep Neural Networks, can be harnessed to perform artistic style transfer. This paper focuses on rendering an image non-photorealistically using Convolutional Neural Networks. However, I verify that in certain cases, this method produces perceptually unappealing results by producing artefacts in the image or distorting important aspects – such as colour, texture, and facial details in the case of portraits – of the image. I argue and conclude that although the production of art by machines has been limited to artistic style transfer so far, within accomplishing the task of artistic style transfer, the combination of Markov Random Fields and the dCNN is able to improve the perceptual quality of non-photorealistically rendered images – while introducing a method for photorealistic rendering of an image – in comparison to the initial method which was purely based on the Convolutional Neural Network (CNN). Finally, when discussing how Generative Adversarial Networks (GANs) trained on a dataset of artworks can be modelled to generate art rather than simply combine the style and content of input images, I argue that masterful and valuable traditional art can be neither replicated nor replaced by an algorithm.

